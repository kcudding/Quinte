---
date: "25/02/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, comment="")


library(rmarkdown)
library(kableExtra)
```

### BREAKPOINT On residuals
```{r}
rm(list=ls())
#read in data supplied by DFO, rename and aggregate into annuual means
library(openxlsx)

my_data <-(as.data.frame(read.csv("E:/homeoffice/kim/Quinte/Quinte2022.csv")))
#rename col in recent file
colnames(my_data)[1]<-"Station_Acronym"
colnames(my_data)[colnames(my_data)=="Kd"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi"] <- "secchi"
colnames(my_data)[colnames(my_data)=="chl"] <- "Chla"

colnames(my_data)[colnames(my_data)=="TotalPhyto"]<-"Phyto_BM"

mmetric="epar" #select which metric to analyze
mlab=expression(Light~attenuation~(m^-1)) 
#mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))


#sscal=1.25 #clorophyll and round 1
sscal=1. #clorophyll and round 1

#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)


agg <- aggregate(list(metric=my_data[mmetric],TP=my_data$TP), 
                 by = list(Station_Acronym=my_data$Station_Acronym, year=my_data$year), 
                 FUN=mean, na.rm=TRUE, na.action="na.pass")
agg2 <- aggregate(list(metricN=my_data[mmetric]), 
                  by = list(Station_Acronym=my_data$Station_Acronym, year=my_data$year), 
                  FUN=length)
agg$n=agg2[,3]
agg$weights <- agg$n/mean(agg$n)
colnames(agg)[3]="metric"
colnames(agg)[4]="TP"

#select sites on which to run analysis
stvec=c("B", "HB",  "C")

stlabel=c("Belleville", "Hay Bay", "Conway")
#select sites on which to run analysis

par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)


spydat=agg[agg$Station_Acronym%in%stvec,]

xyear=c(1972,2008)
spydat=spydat[spydat$year%in%c(1972:2008),]
spydat$Station_Acronym=as.factor(spydat$Station_Acronym)
#str(spydat)

#rm(list=ls())
library(strucchange)
```
We completed a breakpoint analysis on total phosphorus, light attenuation and chlorphyll a. Total phosophorus was a strong predictor of both light attentuation and chlorophyll a, and moreover, has a strong relationship to year. Therefore, to avoid an undo influence of colinearity or concurvity, we provide analyses both on the original data, and on the residuals from a fitted relationship to phosphorus.


### Residual breakpoint analysis for light attentuation

```{r}
site=stvec
bxlab=c("","", "Breaks")
bylab=c("","BIC", "")
ly=expression(paste("Light Attentuated (", m^-1, ")"))
lylab=c("", ly, "")


#TP model
tp1=(lm(metric~TP:Station_Acronym, weights=weights, data=spydat))
tp2=(lm(metric~TP+Station_Acronym, weights=weights, data=spydat))
tp3=(lm(metric~TP:Station_Acronym+Station_Acronym, weights=weights, data=spydat))
cop=AIC(tp1,tp2,tp3)
cop


m1=which.min(cop$AIC)
mod=row.names(cop)[m1]
bestmod=as.name(mod)
```

```{r}
par(mfrow=c(3,1), mar=c(0.5,3,1,1), oma=c(4,3,0,0),
    cex.axis=1.2, cex.lab=1.75, cex.main=1.2, cex.sub=1)
for (i in 1:length(stvec)) {
  pdat=spydat[spydat$Station_Acronym==stvec[i],]
  moddat=as.data.frame(predict(tp2, pdat, interval="confidence"))
mscale=c(0.5, 2.25)
   amscale=mscale
  

  if (i==3) amscale=mscale/2
  plot(metric~TP, data=pdat,xaxt="n",pch=16,col="black",las=2,
      # ann=FALSE, 
       #xlim=xyear, 
      ylim=amscale, bty="l")
      
      #yaxp=c(0,round(2,2),4)
     # )
  lines(moddat$fit~pdat$TP, col="pink", lwd=2)
  lines(moddat$upr~pdat$TP, col="pink", lty=2, lwd=2)
  lines(moddat$lwr~pdat$TP, col="pink", lty=2, lwd=2)
  
if ( i==3)axis(side=1, las=1)
  legend("topleft",stlabel[i], bty="n",
         cex=1.5)
}
 mtext(mlab, side = 2, line = 0, outer = TRUE, at = NA,
        adj = NA, padj = NA, cex = 1.4, col = NA, font = NA)
  mtext(expression(Total~phosophorus~(mg~L^-1)), side = 1, line = +3, outer = TRUE, at = NA,
        adj = NA, padj = NA, cex = 1.4, col = NA, font = NA)
  
  
  treg=as.data.frame(summary(tp2)$coefficients)
  
 
sigstar=ifelse (treg[,4]<0.5, "*", "") 
treg[,4]=formatC(treg[,4], format = "e", digits = 1)
 treg[,4]=paste(treg[,4],sigstar)
 treg[,1:3]=round(treg[,1:3],3)
  
 treg[,4]=formatC(treg[,4], format = "e", digits = 1)
 treg[,1:3]=round(treg[,1:3],3)
regco=kable(treg, digits=4,
            #format="html", table.attr = "style='width:60%;'",
   caption="light~TP")
tsave=footnote(kable_classic(regco),
         general = paste("adj. R squared=", round((summary(tp3)$adj.r.squared),2)),
         footnote_as_chunk = TRUE,
         general_title = "")
tsave

```

There was no difference in AIC (`r c(cop[2,2], cop[3,2])`) or R2 (`r c(summary(tp2)$adj.r.squared,summary(tp2)$adj.r.squared)`) between a global linear model of light attentuation vs total phosophorus with intercept given by site, and a model with slope and intercept specific to each site. both models performed better than a model with a single intercept for all sites, but site specific slopes (AIC=`r cop[1,2]`. R^2=`r  summary(tp1)$adj.r.squared`). We therefore used the global slope model (fig & table) to calculate residuals.

We used the strucchange function to suggest the position and number of breaks in the timeseries, and then fit the corresponding model with data weighted by observation number for the year.



```{r}

mpred=as.data.frame(predict(tp2, spydat, interval="confidence"))
spydat=cbind(spydat, mpred)
spydat$TPres=spydat$metric-spydat$fit

#metric model
tp4=(lm(TPres~year:Station_Acronym+Station_Acronym, weights=weights, data=spydat))
tp5=(lm(TPres~year+Station_Acronym, weights=weights, data=spydat))
tp6=(lm(TPres~year:Station_Acronym, weights=weights, data=spydat))
tp7=(lm(TPres~TP:Station_Acronym+year+Station_Acronym, weights=weights, data=spydat))
tp8=(lm(TPres~TP+year:Station_Acronym, weights=weights, data=spydat))




copref=AIC(tp4,tp5,tp6, tp7, tp8)

```

The best fit linear model for the residual light attentuation included both site specific slope and intercept (AIC=`r copref[1,2]` vs AIC=`r copref[2,2]` for a model with a global slope), and so subsequent analysis was conducted for individual sites. 






```{r}
reglist=list()
#tiff('baseR_figure.tiff', width =85, 
#     height = 180, pointsize = 12,
#     units = 'mm', res = 300)

#jpeg('baseR_figure.jpeg', width =85, 
#     height = 180,
#     units = 'mm', pointsize = 12,
#     quality = 75,
#     res = 300)

par(mfrow=c(3,1), mar=c(0.5,3,1,1), oma=c(4,3,0,0),
    cex.axis=1.2, cex.lab=1.75, cex.main=1.2, cex.sub=1)
for (i in 1:length(stvec)) {
  pdat=spydat[spydat$Station_Acronym==stvec[i],]
  dat=ts(spydat$metric[spydat$Station_Acronym==site[i]], start=spydat$year[1], 
         end=spydat$year[length(spydat$year)])
  tt=1:length(dat)
  mss=which(!complete.cases(pdat))
  if (length(mss)>0) pdat=pdat[-mss,]
  
  #b=breakpoints(dat~1)
  b=breakpoints(TPres ~ year, data=pdat)
  #b=breakpoints(metric ~ year, data=pdat)
  print(b)
cat('\n\n<!-- -->\n\n')
  if (sum(!is.na(b$breakpoints))>0){
  
  # fit segmented model
  fac.ri <- breakfactor(b, label = "seg")
#   if (length(mss)>0){
#  bfac.ri=fac.ri[1:(mss-1)]
#  bfac.ri=c(bfac.ri, NA)
#  bfac.ri=c(bfac.ri, fac.ri[(mss):length(fac.ri)])
#   }else{
#     bfac.ri= fac.ri
  
  
  time=as.factor(fac.ri)
  fm.riT <- lm(TPres ~ time:year, data=pdat, weights=weights)
  fm.ri <- lm(TPres ~ time+year, data=pdat, weights=weights)
  fm.riN <- lm(TPres ~ year, data=pdat,weights=weights)
   fm.riT2 <- lm(TPres ~ time:year+time, data=pdat, weights=weights)
  coret=AIC(fm.ri, fm.riN,fm.riT, fm.riT2)
  print(coret)
  fm.ri=fm.riT2
  summary(fm.ri)
  } else {
    fm.ri <- lm(TPres ~ year, data=pdat,weights=weights)
  }
  
  #table of output
  
reglist[[i]]=fm.ri  
  
#summary(fm.ri)$adj.r.squared

mscale=c(-.5,.5)
  amscale=mscale
 
  if (i==3) amscale[2]=mscale[2]/2
  plot(TPres~year, data=pdat, type="b",xaxt="n",pch=16,col="grey",
      # ann=FALSE, 
       xlim=xyear, ylim=amscale,las=2,bty="l")
      #yaxp=c(0,round(2,2),4))
  
  if ( i==3)axis(side=1, las=1)
  legend("topright",stlabel[i], bty="n",
         cex=1.5)

  bfm=predict( fm.ri, newdata=pdat)
  
  lines(bfm~pdat$year, col = 2, lwd=2)

  
  #convert confidence intervals from julian day to dates
  #and draw
  
  #draw breakpoints & confidence intervals 
 if (sum(!is.na(b$breakpoints))>0){
  ci=confint(b)$confint
  ci=ci[summary(fm.ri)$coefficients[2:(1+length(b$breakpoints)),4]<0.05,]
  hgt=amscale[2]-0.1
#  if (i==3) hgt=4
  tm=nrow(ci)
  if (length(tm)==0) tm=1
  yn=rep(hgt,tm)
  
  if (tm==1) {
    s=1
    xn=pdat$year[ci[1]]
    xx=pdat$year[ci[3]]
    yx=yn
    segments(xn[s], yn[s], xx[s], yx[s], col="blue", lwd=2, lend="square")
    text(pdat$year[ci[2]]-2.5,amscale[2], pdat$year[ci[2]])
    abline(v=pdat$year[ci[2]], lty=2, col="blue")
  } else {
    yn=rep(hgt,tm)
    
  s=1:tm
  
  xn=pdat$year[ci[,1]]
  xx=pdat$year[ci[,3]]
  yx=yn
  segments(xn[s], yn[s], xx[s], yx[s], col="blue", lwd=2, lend="square")
  abline(v=pdat$year[ci[,2]], lty=2, col="blue")
  text(pdat$year[ci[,2]]-2.5,y=amscale[2], pdat$year[ci[,2]])
  }

 }
  
  mtext("Residual light attenuation", side = 2, line = 0, outer = TRUE, at = NA,
        adj = NA, padj = NA, cex = 1.4, col = NA, font = NA)
  mtext("year", side = 1, line = +2, outer = TRUE, at = NA,
        adj = NA, padj = NA, cex = 1.4, col = NA, font = NA)
  

}
legend("bottom", c("data", "model", "breakpoint",
                  "breakpoint CI"),
       lty=c(1,1,2,1), col=c("grey", "red","blue", "blue"), 
       pch=c(16,NA,NA,NA),
       bty="n", cex=1.2, ncol=2)
#dev.off()

##########END BREAKPOINT
```


The best fit breakpoint model for Belleville and Hay Bay allowed for differences in both intercept and slope in each time segment. There were no candidate breakpoints for Conway. There was only one significant breakpoint for Belleville about 1984. Hay Bay data suggested two breakpoints: one sometime in the 80s and another in 1994.


```{r}
i=1
regout=as.data.frame(summary(reglist[[i]])$coefficients) 
sigstar=ifelse (regout[,4]<0.5, "*", "") 
 regout[,4]=formatC(regout[,4], format = "e", digits = 1)
 regout[,4]=paste(regout[,4],sigstar)
 regout[,1:3]=round(regout[,1:3],3)

 rsq=round((summary(reglist[[i]])$adj.r.squared),2)
regco=kable((regout), digits=2,
            #format="html", table.attr = "style='width:60%;'",
   caption=paste("residual light","Site", stvec[i]))
tsave=footnote(kable_classic(regco),
         general = paste("adj. R squared=",rsq),
         footnote_as_chunk = TRUE,
         general_title = "")

#fname=paste0(mmetric,"Site", stvec[i],".png")
tsave

```

```{r}
i=2


regout=as.data.frame(summary(reglist[[i]])$coefficients) 
sigstar=ifelse (regout[,4]<0.5, "*", "") 
 regout[,4]=formatC(regout[,4], format = "e", digits = 1)
 regout[,4]=paste(regout[,4],sigstar)
 regout[,1:3]=round(regout[,1:3],3)
 rsq=round((summary(reglist[[i]])$adj.r.squared),2)
regco=kable((regout), digits=2,
            #format="html", table.attr = "style='width:60%;'",
   caption=paste("residual light","Site", stvec[i]))
tsave=footnote(kable_classic(regco),
         general = paste("adj. R squared=",rsq),
         footnote_as_chunk = TRUE,
         general_title = "")

#fname=paste0(mmetric,"Site", stvec[i],".png")
tsave

#save_kable(tsave,file=fname, density=600, zoom = 1.25, bs_theme = "flatly")


```

```{r}
i=3
regout=as.data.frame(summary(reglist[[i]])$coefficients) 
sigstar=ifelse (regout[,4]<0.5, "*", "") 
 regout[,4]=formatC(regout[,4], format = "e", digits = 1)
 regout[,4]=paste(regout[,4],sigstar)
 regout[,1:3]=round(regout[,1:3],3)
 rsq=round((summary(reglist[[i]])$adj.r.squared),2)
regco=kable((regout), digits=2,
            #format="html", table.attr = "style='width:60%;'",
   caption=paste("residual light","Site", stvec[i]))
tsave=footnote(kable_classic(regco),
         general = paste("adj. R squared=",rsq),
         footnote_as_chunk = TRUE,
         general_title = "")

#fname=paste0(mmetric,"Site", stvec[i],".png")
tsave
#cat('\n\n<!-- -->\n\n')

#save_kable(tsave,file=fname, density=600, zoom = 1.25, bs_theme = "flatly")


```
